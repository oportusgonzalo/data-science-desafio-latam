{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 as pg2\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Leyendo archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos de entrenamiento\n",
    "df_train = pd.read_csv('train_cupid.csv')\n",
    "\n",
    "for col in df_train.columns:\n",
    "    df_train[col] = df_train[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos columnas\n",
    "columns_all = df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos de validacion\n",
    "df_test = pd.read_csv('test_cupid.csv')\n",
    "\n",
    "for col in df_train.columns:\n",
    "    df_test[col] = df_test[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving sets\n",
    "df_train.to_csv('train_cupid.csv', index=False)\n",
    "df_test.to_csv('test_cupid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creando base de datos e importando tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conectando\n",
    "user = 'postgres'\n",
    "password = 'moeg231@'\n",
    "conn_db = pg2.connect(f\"user={user} password={password}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando BD\n",
    "conn_db.autocommit = True\n",
    "cursor = conn_db.cursor()\n",
    "cursor.execute('CREATE DATABASE apellido_nombre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando tablas\n",
    "for table_ in ['train_data', 'test_data']:\n",
    "    cursor.execute(f'create table {table_} (\\\n",
    "            \"age\" INTEGER,\\\n",
    "            \"height\" INTEGER,\\\n",
    "            \"virgo\" INTEGER,\\\n",
    "            \"taurus\" INTEGER,\\\n",
    "            \"scorpio\" INTEGER,\\\n",
    "            \"pisces\" INTEGER,\\\n",
    "            \"libra\" INTEGER,\\\n",
    "            \"leo\" INTEGER,\\\n",
    "            \"gemini\" INTEGER,\\\n",
    "            \"aries\" INTEGER,\\\n",
    "            \"aquarius\" INTEGER,\\\n",
    "            \"cancer\" INTEGER,\\\n",
    "            \"sagittarius\" INTEGER,\\\n",
    "            \"asian\" INTEGER,\\\n",
    "            \"hispanic_latin\" INTEGER,\\\n",
    "            \"black\" INTEGER,\\\n",
    "            \"indian\" INTEGER,\\\n",
    "            \"pacific_islander\" INTEGER,\\\n",
    "            \"native_american\" INTEGER,\\\n",
    "            \"middle_eastern\" INTEGER,\\\n",
    "            \"colorado\" INTEGER,\\\n",
    "            \"new_york\" INTEGER,\\\n",
    "            \"oregon\" INTEGER,\\\n",
    "            \"arizona\" INTEGER,\\\n",
    "            \"hawaii\" INTEGER,\\\n",
    "            \"montana\" INTEGER,\\\n",
    "            \"wisconsin\" INTEGER,\\\n",
    "            \"virginia\" INTEGER,\\\n",
    "            \"spain\" INTEGER,\\\n",
    "            \"nevada\" INTEGER,\\\n",
    "            \"illinois\" INTEGER,\\\n",
    "            \"vietnam\" INTEGER,\\\n",
    "            \"ireland\" INTEGER,\\\n",
    "            \"louisiana\" INTEGER,\\\n",
    "            \"michigan\" INTEGER,\\\n",
    "            \"texas\" INTEGER,\\\n",
    "            \"united_kingdom\" INTEGER,\\\n",
    "            \"massachusetts\" INTEGER,\\\n",
    "            \"north_carolina\" INTEGER,\\\n",
    "            \"idaho\" INTEGER,\\\n",
    "            \"mississippi\" INTEGER,\\\n",
    "            \"new_jersey\" INTEGER,\\\n",
    "            \"florida\" INTEGER,\\\n",
    "            \"minnesota\" INTEGER,\\\n",
    "            \"georgia\" INTEGER,\\\n",
    "            \"utah\" INTEGER,\\\n",
    "            \"washington\" INTEGER,\\\n",
    "            \"west_virginia\" INTEGER,\\\n",
    "            \"connecticut\" INTEGER,\\\n",
    "            \"tennessee\" INTEGER,\\\n",
    "            \"rhode_island\" INTEGER,\\\n",
    "            \"district_of_columbia\" INTEGER,\\\n",
    "            \"canada\" INTEGER,\\\n",
    "            \"missouri\" INTEGER,\\\n",
    "            \"germany\" INTEGER,\\\n",
    "            \"pennsylvania\" INTEGER,\\\n",
    "            \"netherlands\" INTEGER,\\\n",
    "            \"switzerland\" INTEGER,\\\n",
    "            \"mexico\" INTEGER,\\\n",
    "            \"ohio\" INTEGER,\\\n",
    "            \"agnosticism\" INTEGER,\\\n",
    "            \"atheism\" INTEGER,\\\n",
    "            \"catholicism\" INTEGER,\\\n",
    "            \"buddhism\" INTEGER,\\\n",
    "            \"judaism\" INTEGER,\\\n",
    "            \"hinduism\" INTEGER,\\\n",
    "            \"islam\" INTEGER,\\\n",
    "            \"pro_dogs\" INTEGER,\\\n",
    "            \"pro_cats\" INTEGER,\\\n",
    "            \"spanish\" INTEGER,\\\n",
    "            \"chinese\" INTEGER,\\\n",
    "            \"french\" INTEGER,\\\n",
    "            \"german\" INTEGER,\\\n",
    "            \"single\" INTEGER,\\\n",
    "            \"seeing_someone\" INTEGER,\\\n",
    "            \"available\" INTEGER,\\\n",
    "            \"employed\" INTEGER,\\\n",
    "            \"income_between_25_50\" INTEGER,\\\n",
    "            \"income_between_50_75\" INTEGER,\\\n",
    "            \"income_over_75\" INTEGER,\\\n",
    "            \"drugs_often\" INTEGER,\\\n",
    "            \"drugs_sometimes\" INTEGER,\\\n",
    "            \"drinks_not_at_all\" INTEGER,\\\n",
    "            \"drinks_often\" INTEGER,\\\n",
    "            \"drinks_rarely\" INTEGER,\\\n",
    "            \"drinks_socially\" INTEGER,\\\n",
    "            \"drinks_very_often\" INTEGER,\\\n",
    "            \"orientation_gay\" INTEGER,\\\n",
    "            \"orientation_straight\" INTEGER,\\\n",
    "            \"sex_m\" INTEGER,\\\n",
    "            \"smokes_sometimes\" INTEGER,\\\n",
    "            \"smokes_trying_to_quit\" INTEGER,\\\n",
    "            \"smokes_when_drinking\" INTEGER,\\\n",
    "            \"smokes_yes\" INTEGER,\\\n",
    "            \"body_type_overweight\" INTEGER,\\\n",
    "            \"body_type_regular\" INTEGER,\\\n",
    "            \"education_high_school\" INTEGER,\\\n",
    "            \"education_undergrad_university\" INTEGER);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set de columnas\n",
    "train_set = 'train_data values ('\n",
    "test_set = 'test_data values ('\n",
    "\n",
    "for col in df_train.columns[df_train.columns != 'index']:\n",
    "    if col != 'education_undergrad_university':\n",
    "        train_set += '%s' + ', '\n",
    "        test_set += '%s' + ', '\n",
    "    else:\n",
    "        train_set += '%s'\n",
    "        test_set += '%s'\n",
    "\n",
    "train_set += ')'\n",
    "test_set += ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingestamos datos de entrenamiento y validacion a las tablas respectivas en nuestra base de datos\n",
    "for set_ in ['train_cupid', 'test_cupid']:\n",
    "    with open(f'./{set_}.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        \n",
    "        if set_ == 'train_cupid':\n",
    "            insert_string = train_set\n",
    "        else:\n",
    "            insert_string = test_set\n",
    "\n",
    "        for row in reader:\n",
    "            cursor.execute(f\"INSERT INTO {insert_string}\", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Entrenamiento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conjunto de entrenamiento\n",
    "cursor.execute(\"SELECT * FROM train_data;\")\n",
    "columnas_train = cursor.fetchall()\n",
    "X_train = pd.DataFrame(list(columnas_train))\n",
    "X_train.columns = columns_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando variables objetivo\n",
    "y_single_train = X_train['single']\n",
    "y_seeing_train = X_train['seeing_someone']\n",
    "y_aval_train = X_train['available']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminando variables objetivo de la matriz de atributos\n",
    "X_train = X_train.drop(['single', 'seeing_someone', 'available'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicion de modelos a implementar\n",
    "model_dict = {\n",
    "    'logistic': LogisticRegression(), \n",
    "    'dec_tree': DecisionTreeClassifier(max_depth=5), \n",
    "    'rdm_forest': RandomForestClassifier(max_depth=5),\n",
    "    'grad_boost': GradientBoostingClassifier(),  \n",
    "    'ada_boost': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5)),\n",
    "    'bernoulli': BernoulliNB(), \n",
    "    'svc': SVC(kernel='rbf')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {\n",
    "    'single': y_single_train,\n",
    "    'seeing': y_seeing_train,\n",
    "    'aval': y_aval_train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_, model_ in model_dict.items():\n",
    "    for var_ in ['single', 'seeing', 'aval']:\n",
    "        model_temp = model_.fit(X_train, var_dict[var_])\n",
    "        pickle.dump(model_temp, open(f'pickles/model_{name_}_{var_}.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conjunto de validacion\n",
    "cursor.execute(\"SELECT * FROM test_data;\")\n",
    "columnas_test = cursor.fetchall()\n",
    "X_test = pd.DataFrame(list(columnas_test))\n",
    "X_test.columns = columns_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando variables objetivo\n",
    "y_single_test = X_test['single']\n",
    "y_seeing_test = X_test['seeing_someone']\n",
    "y_aval_test = X_test['available']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminando variables objetivo de la matriz de atributos\n",
    "X_test = X_test.drop(['single', 'seeing_someone', 'available'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict_pred = {\n",
    "    'single': y_single_test,\n",
    "    'seeing': y_seeing_test,\n",
    "    'aval': y_aval_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_temp = pickle.load(open(f'pickles/model_ada_boost_aval.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: logistic - V.O: single\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.02      0.04      1616\n",
      "           1       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.67      0.51      0.50     19943\n",
      "weighted avg       0.88      0.92      0.88     19943\n",
      "\n",
      "Model: logistic - V.O: seeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n",
      "Model: logistic - V.O: aval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n",
      "Model: dec_tree - V.O: single\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1616\n",
      "           1       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.46      0.50      0.48     19943\n",
      "weighted avg       0.84      0.92      0.88     19943\n",
      "\n",
      "Model: dec_tree - V.O: seeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n",
      "Model: dec_tree - V.O: aval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n",
      "Model: rdm_forest - V.O: single\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1616\n",
      "           1       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.46      0.50      0.48     19943\n",
      "weighted avg       0.84      0.92      0.88     19943\n",
      "\n",
      "Model: rdm_forest - V.O: seeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n",
      "Model: rdm_forest - V.O: aval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n",
      "Model: grad_boost - V.O: single\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.03      0.05      1616\n",
      "           1       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.72      0.51      0.50     19943\n",
      "weighted avg       0.89      0.92      0.88     19943\n",
      "\n",
      "Model: grad_boost - V.O: seeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n",
      "Model: grad_boost - V.O: aval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n",
      "Model: ada_boost - V.O: single\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.10      0.14      1616\n",
      "           1       0.92      0.97      0.95     18327\n",
      "\n",
      "    accuracy                           0.90     19943\n",
      "   macro avg       0.59      0.54      0.54     19943\n",
      "weighted avg       0.87      0.90      0.88     19943\n",
      "\n",
      "Model: ada_boost - V.O: seeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     19163\n",
      "           1       0.06      0.03      0.04       780\n",
      "\n",
      "    accuracy                           0.95     19943\n",
      "   macro avg       0.51      0.51      0.50     19943\n",
      "weighted avg       0.93      0.95      0.94     19943\n",
      "\n",
      "Model: ada_boost - V.O: aval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     19163\n",
      "           1       0.06      0.03      0.04       780\n",
      "\n",
      "    accuracy                           0.95     19943\n",
      "   macro avg       0.51      0.51      0.50     19943\n",
      "weighted avg       0.93      0.95      0.94     19943\n",
      "\n",
      "Model: bernoulli - V.O: single\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.05      0.08      1616\n",
      "           1       0.92      0.99      0.95     18327\n",
      "\n",
      "    accuracy                           0.91     19943\n",
      "   macro avg       0.61      0.52      0.52     19943\n",
      "weighted avg       0.87      0.91      0.88     19943\n",
      "\n",
      "Model: bernoulli - V.O: seeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.09      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.52      0.50      0.49     19943\n",
      "weighted avg       0.93      0.96      0.94     19943\n",
      "\n",
      "Model: bernoulli - V.O: aval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.09      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.52      0.50      0.49     19943\n",
      "weighted avg       0.93      0.96      0.94     19943\n",
      "\n",
      "Model: svc - V.O: single\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1616\n",
      "           1       0.92      1.00      0.96     18327\n",
      "\n",
      "    accuracy                           0.92     19943\n",
      "   macro avg       0.46      0.50      0.48     19943\n",
      "weighted avg       0.84      0.92      0.88     19943\n",
      "\n",
      "Model: svc - V.O: seeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n",
      "Model: svc - V.O: aval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19163\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "    accuracy                           0.96     19943\n",
      "   macro avg       0.48      0.50      0.49     19943\n",
      "weighted avg       0.92      0.96      0.94     19943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# realizamos predicciones y visualizamos resultados\n",
    "\n",
    "for name_, model_instance in model_dict.items():\n",
    "    for var_ in ['single', 'seeing', 'aval']:\n",
    "        mod_temp = pickle.load(open(f'pickles/model_{name_}_{var_}.sav', 'rb'))\n",
    "        print(f'Model: {name_} - V.O: {var_}')\n",
    "        print(classification_report(var_dict_pred[var_], mod_temp.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predicción de queries específicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicion de variables a obtener en cada query\n",
    "q1 = ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
    "q2 = ['income_over_75', 'french', 'german','orientation_straight', 'new_york']\n",
    "q3 = ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
    "q4 = ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_creation_dict = {\n",
    "    'query_1': 'create table {} (\"atheism\" INTEGER, \"asian\" INTEGER, \"employed\" INTEGER, \"pro_dogs\" INTEGER, \"chinese\" INTEGER, \"single_yhat\" REAL);',\n",
    "    'query_2': 'create table {} (\"income_over_75\" INTEGER, \"french\" INTEGER, \"german\" INTEGER, \"orientation_straight\" INTEGER, \"new_york\" INTEGER, \"single_yhat\" REAL);',\n",
    "    'query_3': 'create table {} (\"education_undergrad_university\" INTEGER, \"body_type_regular\" INTEGER, \"pro_dogs\" INTEGER, \"employed\" INTEGER, \"single_yhat\" REAL);',\n",
    "    'query_4': 'create table {} (\"taurus\" INTEGER, \"indian\" INTEGER, \"washington\" INTEGER, \"income_between_50_75\" INTEGER, \"hinduism\" INTEGER, \"single_yhat\" REAL);'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_values(table_name, structure_, df_temp):\n",
    "    for index, row in df_temp.iterrows():\n",
    "        cursor.execute(f\"INSERT INTO {table_name} VALUES {structure_}\", row.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: logistic - V.O: single - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: logistic - V.O: single - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: logistic - V.O: single - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: logistic - V.O: single - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: logistic - V.O: seeing - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: logistic - V.O: seeing - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: logistic - V.O: seeing - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: logistic - V.O: seeing - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: logistic - V.O: aval - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: logistic - V.O: aval - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: logistic - V.O: aval - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: logistic - V.O: aval - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: dec_tree - V.O: single - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: dec_tree - V.O: single - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: dec_tree - V.O: single - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: dec_tree - V.O: single - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: dec_tree - V.O: seeing - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: dec_tree - V.O: seeing - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: dec_tree - V.O: seeing - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: dec_tree - V.O: seeing - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: dec_tree - V.O: aval - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: dec_tree - V.O: aval - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: dec_tree - V.O: aval - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: dec_tree - V.O: aval - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: rdm_forest - V.O: single - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: rdm_forest - V.O: single - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: rdm_forest - V.O: single - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: rdm_forest - V.O: single - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: rdm_forest - V.O: seeing - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: rdm_forest - V.O: seeing - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: rdm_forest - V.O: seeing - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: rdm_forest - V.O: seeing - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: rdm_forest - V.O: aval - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: rdm_forest - V.O: aval - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: rdm_forest - V.O: aval - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: rdm_forest - V.O: aval - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: grad_boost - V.O: single - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: grad_boost - V.O: single - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: grad_boost - V.O: single - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: grad_boost - V.O: single - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: grad_boost - V.O: seeing - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: grad_boost - V.O: seeing - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: grad_boost - V.O: seeing - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: grad_boost - V.O: seeing - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: grad_boost - V.O: aval - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: grad_boost - V.O: aval - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: grad_boost - V.O: aval - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: grad_boost - V.O: aval - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: ada_boost - V.O: single - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: ada_boost - V.O: single - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: ada_boost - V.O: single - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: ada_boost - V.O: single - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: ada_boost - V.O: seeing - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: ada_boost - V.O: seeing - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: ada_boost - V.O: seeing - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: ada_boost - V.O: seeing - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: ada_boost - V.O: aval - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: ada_boost - V.O: aval - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: ada_boost - V.O: aval - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: ada_boost - V.O: aval - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: bernoulli - V.O: single - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: bernoulli - V.O: single - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: bernoulli - V.O: single - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: bernoulli - V.O: single - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: bernoulli - V.O: seeing - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: bernoulli - V.O: seeing - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: bernoulli - V.O: seeing - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: bernoulli - V.O: seeing - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: bernoulli - V.O: aval - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: bernoulli - V.O: aval - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: bernoulli - V.O: aval - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: bernoulli - V.O: aval - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: svc - V.O: single - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: svc - V.O: single - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: svc - V.O: single - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: svc - V.O: single - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: svc - V.O: seeing - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: svc - V.O: seeing - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: svc - V.O: seeing - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: svc - V.O: seeing - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n",
      "Model: svc - V.O: aval - Query: ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese']\n",
      "Model: svc - V.O: aval - Query: ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york']\n",
      "Model: svc - V.O: aval - Query: ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed']\n",
      "Model: svc - V.O: aval - Query: ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']\n"
     ]
    }
   ],
   "source": [
    "# calculamos los perfiles de acuerdo a cada grupo de variables e ingestamos en la BD\n",
    "\n",
    "for name_, model_instance in model_dict.items():\n",
    "    for var_ in ['single', 'seeing', 'aval']:\n",
    "        for query_ in [q1, q2, q3, q4]:\n",
    "            print(f'Model: {name_} - V.O: {var_} - Query: {query_}')\n",
    "            # creacion de perfiles\n",
    "            df_temp = pd.DataFrame(create_crosstab(f'pickles/model_{name_}_{var_}.sav', X_test, var_dict_pred[var_], query_)).reset_index()\n",
    "            # creacion de tablas en BD e ingestamos datos\n",
    "            if query_ == q1:\n",
    "                cursor.execute(table_creation_dict['query_1'].format(f'{name_}_{var_}_query_1'))\n",
    "                insert_values(f'{name_}_{var_}_query_1', '(%s, %s, %s, %s, %s, %s)', df_temp)\n",
    "            elif query_ == q2:\n",
    "                cursor.execute(table_creation_dict['query_1'].format(f'{name_}_{var_}_query_2'))\n",
    "                insert_values(f'{name_}_{var_}_query_2', '(%s, %s, %s, %s, %s, %s)', df_temp)\n",
    "            elif query_ == q3:\n",
    "                cursor.execute(table_creation_dict['query_1'].format(f'{name_}_{var_}_query_3'))\n",
    "                insert_values(f'{name_}_{var_}_query_3', '(%s, %s, %s, %s, %s)', df_temp)\n",
    "            else:\n",
    "                cursor.execute(table_creation_dict['query_1'].format(f'{name_}_{var_}_query_4'))\n",
    "                insert_values(f'{name_}_{var_}_query_4', '(%s, %s, %s, %s, %s, %s)', df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_db.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Exportación base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1b303acd0c11ca3b4a72b7c4bcfa9e6d93c50d16ae889b8d4c17cd8b47c442f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
