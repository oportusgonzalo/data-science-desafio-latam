{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hito 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preliminares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se detallan las características del problema a evaluar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Problema (Análisis de sentimientos en Twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema corresponde a uno de análisis de texto, donde queremos identificar el sentimiento asociado a un texto; el cual se refiere a un tweet.\n",
    "\n",
    "Dado ello, es un problema de clasificación.\n",
    "\n",
    "Objetivo: identificar si un tweet tiene polaridad positiva o negativa (sentimiento expresado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variable objetivo: describe una emocion que resume el contenido de un tweet. Para conveniencia del trabajo, estas serán transformadas a emociones positivas o negativas de acuerdo a su morfología.\n",
    "\n",
    "* Atributos: inicialmente existen textos que son tweets escritos en la plataforma de Twitter. Sin embargo, con objetivo de crear atributos para la predicción de emociones, transformaremos dichos textos en vectores de ocurrencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Modelos a implementar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el problema a estudiar es un problema de clasificación, proponemos la implementación de los siguientes modelos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression: método de clasificación que presente una fácil implementación y en general, un buen desempeño.\n",
    "\n",
    "* KMeans: \n",
    "\n",
    "* Linear Discriminant Analysis: algoritmo supervisado (tenemos conocimiento previo sobre la existencia de las clases y) y generativo (buscamos aprender sobre las clases a partir de los atributos X).\n",
    "\n",
    "* Random Forest Classifier: dado que es un buen predictor para clasificadores al promediar el desempeño de un grupo de clasificadores, e implementa un proceso de validación cruzada con un sample menor al número total de atributos disponibles; permitiendo evaluar el desempeño \"out-of-bag\" en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar modelos y grillas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Métricas y estrategia de división de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score, roc_auc_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Procesamiento tentativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aspectos Computacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from static import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lectura de datos\n",
    "data = pd.read_csv('training_tweets.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 limpieza de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando normalización y lemmatizacion a los tweets\n",
    "df_clean = nlp_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean.loc[:, ['content_clean', 'sentiment']]\n",
    "df.rename(columns={'content_clean': 'content'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Transformando emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {\n",
    "    'worry': 'negativa',\n",
    "    'happiness': 'positiva',\n",
    "    'sadness': 'negativa',\n",
    "    'love': 'positiva',\n",
    "    'surprise': 'positiva',\n",
    "    'fun': 'positiva',\n",
    "    'relief': 'positiva',\n",
    "    'hate': 'negativa',\n",
    "    'empty': 'negativa',\n",
    "    'enthusiasm': 'positiva',\n",
    "    'boredom': 'negativa',\n",
    "    'anger': 'negativa'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazando emociones\n",
    "df['sentiment'] = df['sentiment'].replace(emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazando emocion neutral\n",
    "binary = ['negativa', 'positiva']\n",
    "df['sentiment'] = [i.replace('neutral', np.random.choice(binary, 1, p=[0.51, 0.49])[0]) for i in df['sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Transformamos el conjunto de datos en una matriz que represente la ocurrencia de cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Vectorizer Object\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo con los\n",
    "X = vectorizer.fit_transform(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducimos el espacio eliminando palabras insignificantes\n",
    "df_count = df_count.iloc[:, 899:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntamos los conjuntos de datos\n",
    "df = pd.concat([df, df_count], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>aaaaaaaaaamazing</th>\n",
       "      <th>aaaaaaaafternoon</th>\n",
       "      <th>aaaaaaaahhhhhhhh</th>\n",
       "      <th>aaaaaah</th>\n",
       "      <th>aaaaahhhh</th>\n",
       "      <th>aaaaall</th>\n",
       "      <th>aaaaand</th>\n",
       "      <th>aaaaaoouoouoouu</th>\n",
       "      <th>...</th>\n",
       "      <th>zstanu</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuccini</th>\n",
       "      <th>zuljin</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zuluxhosa</th>\n",
       "      <th>zum</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zune</th>\n",
       "      <th>zwarte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy mama day to all mother</td>\n",
       "      <td>positiva</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am lost . please help me find a good home .</td>\n",
       "      <td>negativa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes yes i am networking whore to the fullest ....</td>\n",
       "      <td>positiva</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you wish that would have been your tweet after...</td>\n",
       "      <td>positiva</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>now i am doing the microeconomics project ihat...</td>\n",
       "      <td>negativa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment  \\\n",
       "0                       happy mama day to all mother  positiva   \n",
       "1      i am lost . please help me find a good home .  negativa   \n",
       "2  yes yes i am networking whore to the fullest ....  positiva   \n",
       "3  you wish that would have been your tweet after...  positiva   \n",
       "4  now i am doing the microeconomics project ihat...  negativa   \n",
       "\n",
       "   aaaaaaaaaamazing  aaaaaaaafternoon  aaaaaaaahhhhhhhh  aaaaaah  aaaaahhhh  \\\n",
       "0                 0                 0                 0        0          0   \n",
       "1                 0                 0                 0        0          0   \n",
       "2                 0                 0                 0        0          0   \n",
       "3                 0                 0                 0        0          0   \n",
       "4                 0                 0                 0        0          0   \n",
       "\n",
       "   aaaaall  aaaaand  aaaaaoouoouoouu  ...  zstanu  zu  zuccini  zuljin  zulu  \\\n",
       "0        0        0                0  ...       0   0        0       0     0   \n",
       "1        0        0                0  ...       0   0        0       0     0   \n",
       "2        0        0                0  ...       0   0        0       0     0   \n",
       "3        0        0                0  ...       0   0        0       0     0   \n",
       "4        0        0                0  ...       0   0        0       0     0   \n",
       "\n",
       "   zuluxhosa  zum  zumba  zune  zwarte  \n",
       "0          0    0      0     0       0  \n",
       "1          0    0      0     0       0  \n",
       "2          0    0      0     0       0  \n",
       "3          0    0      0     0       0  \n",
       "4          0    0      0     0       0  \n",
       "\n",
       "[5 rows x 26833 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 26833)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisis exploratorio: palabras mas comunes y distribucion de clases en vector objetivo\n",
    "# patron de datos perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1b303acd0c11ca3b4a72b7c4bcfa9e6d93c50d16ae889b8d4c17cd8b47c442f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
